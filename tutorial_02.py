# -*- coding: utf-8 -*-
"""Tutorial_02.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18rckyuN9dGMSWDOi217GkJjNVG8dXxyR
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.datasets import mnist

(x_train, y_train), (x_text, y_text) = mnist.load_data()

x_train = x_train.reshape(-1, 28*28).astype("float32") / 255.0
x_text  = x_text.reshape(-1, 28*28).astype("float32") / 255.0

print(x_train.shape)
print(x_text.shape)

# SEQUENTIAL API (Very convenient, not very flexible)
model = keras.Sequential(
    [
     keras.Input(shape = (28*28)),
     layers.Dense(512, activation = "relu"),
     layers.Dense(256, activation = "relu"),
     layers.Dense(10),
    ]
)

model = keras.Sequential()
model.add(keras.Input(shape = 784))
model.add(layers.Dense(512, activation="relu"))
print(model.summary())
model.add(layers.Dense(256, activation="relu", name = "my_layer"))
model.add(layers.Dense(10))

model = keras.Model(inputs = model.inputs,
                    outputs = [layer.output for layer in model.layers])
features = model.predict(x_train)

for feature in features:
  print(feature.shape)
print("aaa")

print(model.summary())

# Functional API (A bit more flexible)

inputs = keras.Input(shape=784)
x = layers.Dense(512, activation="relu", name = "first_layer")(inputs)
x = layers.Dense(256, activation="relu", name = "second_layer")(x)
outputs = layers.Dense(10, activation="softmax")(x)
model = keras.Model(inputs = inputs, outputs = outputs)

model.compile(
    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),
    optimizer = keras.optimizers.Adam(lr = 0.001),
    metrics = ["accuracy"],
)

model.fit(x_train, y_train, batch_size = 32, epochs = 5, verbose = 2)
model.evaluate(x_text, y_text, batch_size = 32, verbose = 2)

